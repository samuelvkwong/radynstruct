# Copy this file to .env and fill in your values

# ============================================
# API Keys
# ============================================
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# Get your key at: https://console.anthropic.com/

# OPENAI_API_KEY=your_openai_api_key_here  # Alternative to Anthropic
# Get your key at: https://platform.openai.com/

# ============================================
# AI Provider Configuration
# ============================================
# AI_PROVIDER: Choose which AI provider to use
# Options: "anthropic", "openai", "ollama"
# If not set, auto-detects based on available API keys (Anthropic → OpenAI → Ollama)
AI_PROVIDER=ollama

# AI_MODEL: Model name to use with the selected provider
# Examples:
#   - Anthropic: "claude-sonnet-4-20250514", "claude-3-5-sonnet-20241022"
#   - OpenAI: "gpt-4-turbo-preview", "gpt-4o"
#   - Ollama: "llama3", "mistral", "codellama"
AI_MODEL=claude-sonnet-4-20250514

# ============================================
# Ollama Configuration (for local AI)
# ============================================
# OLLAMA_BASE_URL: URL where Ollama is running
# Default: http://localhost:11434
# For Docker, use: http://host.docker.internal:11434
OLLAMA_BASE_URL=http://host.docker.internal:11434

# OLLAMA_MODEL: Which Ollama model to use
# Default: gemma3
# Run "ollama list" to see available models
OLLAMA_MODEL=gemma3

# ============================================
# Optional: Production Settings
# ============================================
# SECRET_KEY: Secret key for JWT token generation
# Only needed for production deployments
# Generate with: openssl rand -hex 32
# SECRET_KEY=your_secret_key_here
